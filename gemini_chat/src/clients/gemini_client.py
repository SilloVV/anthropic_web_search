"""Client pour l'API Gemini"""

import asyncio
import sys
from typing import List, Optional, Generator, Any, Set
from pathlib import Path
from google.genai import types
from google import genai

from ..utils.config import Config
from ..models.message import ChatMessage, MessageRole


class DuplicateFileError(Exception):
    """Exception lev√©e quand on tente d'uploader un fichier d√©j√† pr√©sent"""
    def __init__(self, file_path: Path, existing_name: str):
        self.file_path = file_path
        self.existing_name = existing_name
        super().__init__(f"Le fichier '{file_path.name}' est d√©j√† upload√© sous le nom '{existing_name}'")


class GeminiClient:
    """Client pour interagir avec l'API Gemini"""
    
    def __init__(self, config: Config):
        self.config = config
        self.client = genai.Client(api_key=config.gemini_api_key)
        self.chat = None
        self.uploaded_files: List[dict] = []
        self.files_sent_to_chat: Set[str] = set()  # Track des fichiers d√©j√† envoy√©s au chat actuel
    
    def initialize_chat(self, tools: Optional[List] = None) -> None:
        """Initialise une nouvelle session de chat"""
        chat_config = types.GenerateContentConfig(
            system_instruction=(
                "Tu es un expert juridique fran√ßais. Tu peux analyser des documents PDF "
                "et r√©pondre aux questions les concernant.\n\n"
                "Tu as la capacit√© de faire des tableaux por pr√©senter des informations de mani√®re claire.\n\n"
                
                "R√àGLES DE RECHERCHE AVEC PERPLEXITY :\n"
                "1. Si la question est une simple salutation, politesse ou remerciement : r√©ponds directement SANS outil\n\n"
                
                "2. Si la question ne concerne AUCUN document upload√© ET n√©cessite des informations d'internet :\n"
                "   ‚Üí Utilise 'perplexity_direct_search' (l'utilisateur recevra directement la r√©ponse compl√®te)\n\n"
                
                "3. Si la question concerne le contenu d'articles de lois , jurisprudence ou r√©glementation :\n"
                "   ‚Üí Utilise 'perplexity_direct_search' (tu recevras une r√©ponse directe √† l'utilisateur)\n\n"
                
                "4. Si la question concerne un document upload√© ET tu as besoin d'informations compl√©mentaires :\n"
                "   ‚Üí Utilise 'perplexity_help_search' (tu recevras des informations √† int√©grer dans ta synth√®se)\n\n"
                
                "IMPORTANT :\n"
                "- perplexity_direct_search : r√©ponse finale directe √† l'utilisateur avec sources\n"
                "- perplexity_help_search : informations compl√©mentaires pour enrichir TA r√©ponse\n"
                "- Ne mentionne jamais ces outils dans tes r√©ponses, utilise-les de mani√®re transparente\n\n"
                
                "EXEMPLES D'USAGE :\n"
                "- 'Salut' ‚Üí r√©ponse directe\n"
                "- 'Quelle est la jurisprudence r√©cente sur les contrats de travail ?' (sans document) ‚Üí perplexity_direct_search\n"
                "- 'Que dit l'article 1234-5 du Code du travail ?' ‚Üí perplexity_direct_search\n"
                "- 'Ce contrat est-il conforme √† la r√©glementation actuelle ?' (avec document) ‚Üí perplexity_help_search\n"
                "- 'Explique-moi ce document' (avec document) ‚Üí r√©ponse directe"
            ),
            max_output_tokens=self.config.max_tokens,
            temperature=self.config.temperature,
            tools=tools
        )
        
        self.chat = self.client.chats.create(
            model="gemini-2.0-flash",
            config=chat_config
        )
        
        # R√©initialiser le tracking des fichiers envoy√©s pour le nouveau chat
        self.files_sent_to_chat.clear()
    
    def _is_file_already_uploaded(self, file_path: Path) -> Optional[str]:
        """
        V√©rifie si un fichier est d√©j√† upload√© en comparant les chemins absolus.
        
        Returns:
            Le nom du fichier existant si trouv√©, None sinon
        """
        absolute_path = file_path.resolve()
        
        for file_info in self.uploaded_files:
            existing_path = Path(file_info['path']).resolve()
            if absolute_path == existing_path:
                return file_info['name']
        
        return None
    
    def get_uploaded_file_paths(self) -> List[str]:
        """Retourne la liste des chemins absolus des fichiers upload√©s (pour debug)"""
        return [str(Path(file_info['path']).resolve()) for file_info in self.uploaded_files]
    
    def upload_file(self, file_path: Path) -> Optional[dict]:
        """Upload un fichier vers Gemini avec v√©rification des doublons"""
        try:
            if not file_path.exists():
                raise FileNotFoundError(f"Le fichier {file_path} n'existe pas")
            
            if file_path.suffix.lower() != '.pdf':
                raise ValueError("Seuls les fichiers PDF sont support√©s")
            
            # V√©rifier les doublons
            existing_name = self._is_file_already_uploaded(file_path)
            if existing_name:
                raise DuplicateFileError(file_path, existing_name)
            
            uploaded_file = self.client.files.upload(file=file_path)
            
            # Utiliser le chemin absolu comme identifiant unique
            absolute_path = file_path.resolve()
            
            file_info = {
                'file': uploaded_file,
                'name': file_path.name,
                'path': str(absolute_path),  # Stocker le chemin absolu
                'size': file_path.stat().st_size,
                'id': str(absolute_path)  # Identifiant bas√© sur le chemin absolu
            }
            
            self.uploaded_files.append(file_info)
            return file_info
            
        except Exception as e:
            # Re-lever les exceptions personnalis√©es sans modification
            if isinstance(e, DuplicateFileError):
                raise
            raise Exception(f"Erreur lors de l'upload: {e}")
    
    def remove_file(self, index: int) -> bool:
        """Supprime un fichier upload√© de la liste des fichiers upload√©s"""
        if 0 <= index < len(self.uploaded_files):
            file_info = self.uploaded_files.pop(index)
            # Retirer aussi du tracking si pr√©sent
            self.files_sent_to_chat.discard(file_info.get('id'))
            return True
        return False
    
    def clear_files(self) -> None:
        """Efface tous les fichiers upload√©s"""
        self.uploaded_files.clear()
        self.files_sent_to_chat.clear()
    
    def get_files_info(self) -> List[dict]:
        """Retourne les informations des fichiers upload√©s"""
        return self.uploaded_files.copy()
    
    def get_new_files(self) -> List[dict]:
        """Retourne les fichiers qui n'ont pas encore √©t√© envoy√©s au chat"""
        return [
            file_info for file_info in self.uploaded_files 
            if file_info.get('id') not in self.files_sent_to_chat
        ]
    
    def mark_files_as_sent(self, file_infos: List[dict]) -> None:
        """Marque les fichiers comme envoy√©s au chat"""
        for file_info in file_infos:
            self.files_sent_to_chat.add(file_info.get('id'))
    
    def reset_file_tracking(self) -> None:
        """Remet √† z√©ro le tracking des fichiers (pour forcer leur re-envoi)"""
        self.files_sent_to_chat.clear()
    
    def send_message_stream(self, message: str, force_include_all_files: bool = False) -> Generator[str, None, None]:
        """
        Envoie un message et retourne un g√©n√©rateur de r√©ponse avec gestion am√©lior√©e des function calls.
        
        Args:
            message: Le message √† envoyer
            force_include_all_files: Si True, inclut tous les fichiers m√™me s'ils ont d√©j√† √©t√© envoy√©s
        """
        if not self.chat:
            raise RuntimeError("Chat non initialis√©")
        
        # Pr√©parer le contenu
        content_parts = [message]
        
        # D√©terminer quels fichiers ajouter
        if force_include_all_files:
            files_to_send = self.uploaded_files.copy()
        else:
            # Inclure automatiquement seulement les nouveaux fichiers
            files_to_send = self.get_new_files()
        
        # Ajouter les fichiers d√©termin√©s
        for file_info in files_to_send:
            content_parts.append(file_info['file'])
        
        # Marquer les fichiers comme envoy√©s
        if files_to_send:
            self.mark_files_as_sent(files_to_send)
            print(f"üìé {len(files_to_send)} fichier(s) ajout√©(s) au contexte: {[f['name'] for f in files_to_send]}")
        
        # Envoyer et streamer la r√©ponse
        response_stream = self.chat.send_message_stream(content_parts)
        
        # Variables pour collecter les function calls
        collected_function_calls: List[Any] = []
        has_text_content = False
        
        # Variables pour compter les tokens de cette interaction
        interaction_total_prompt_tokens = 0
        interaction_total_output_tokens = 0
        prompt_tokens_counted = False

        # Traiter le streaming
        for chunk in response_stream:
            # Compter les tokens √† partir des m√©tadonn√©es d'utilisation
            if hasattr(chunk, 'usage_metadata') and chunk.usage_metadata:
                # Tokens d'entr√©e (prompt)
                if hasattr(chunk.usage_metadata, 'prompt_token_count'):
                    prompt_tokens_value_from_chunk = chunk.usage_metadata.prompt_token_count
                    if not prompt_tokens_counted:
                        interaction_total_prompt_tokens = prompt_tokens_value_from_chunk if prompt_tokens_value_from_chunk is not None else 0
                        prompt_tokens_counted = True
                
                # Tokens de sortie (candidates/g√©n√©r√©s)
                if hasattr(chunk.usage_metadata, 'candidates_token_count'):
                    output_tokens_value_from_chunk = chunk.usage_metadata.candidates_token_count
                    if output_tokens_value_from_chunk is not None:
                        interaction_total_output_tokens += output_tokens_value_from_chunk
            
            # Collecter les "function calls"
            try:
                if hasattr(chunk, 'candidates') and chunk.candidates:
                    candidate = chunk.candidates[0]
                    if hasattr(candidate, 'content') and candidate.content and hasattr(candidate.content, 'parts'):
                        for part in candidate.content.parts:
                            if hasattr(part, 'function_call') and part.function_call:
                                collected_function_calls.append(part.function_call)
            except Exception as e:
                print(f"AVERTISSEMENT: Erreur lors du parsing d'un function call: {e}", file=sys.stderr)
                pass
            
            # V√©rifier s'il y a du contenu texte
            if hasattr(chunk, 'text') and chunk.text:
                has_text_content = True
            
            # Afficher le texte en streaming seulement s'il n'y a pas de function calls
            if not collected_function_calls and has_text_content and hasattr(chunk, 'text') and chunk.text:
                yield chunk.text
        
        # Traitement des function calls collect√©s
        if collected_function_calls:
            for function_call in collected_function_calls:
                function_name = getattr(function_call, 'name', '')
                args = getattr(function_call, 'args', {})
                query = args.get("query", "") if hasattr(args, 'get') else ""
                
                if function_name == "perplexity_direct_search":
                    # Recherche directe - r√©ponse imm√©diate √† l'utilisateur
                    yield f"FUNCTION_CALL:perplexity_direct_search:{query}"
                    
                elif function_name == "perplexity_help_search":
                    # Recherche d'aide - informations pour Gemini
                    yield f"FUNCTION_CALL:perplexity_help_search:{query}"
                    
                else:
                    # Function call non reconnu
                    yield f"FUNCTION_CALL_UNKNOWN:{function_name}:{query}"

        # Yield les comptes totaux de tokens
        yield f"\nGEMINI_PROMPT_TOKENS : {interaction_total_prompt_tokens}\n"
        yield f"GEMINI_OUTPUT_TOKENS : {interaction_total_output_tokens}\n"
        
        # Prix
        input_price = (interaction_total_prompt_tokens * self.config.gemini_input_price_per_token) 
        output_price = (interaction_total_output_tokens * self.config.gemini_output_price_per_token)
        yield f"GEMINI_TOTAL_INPUT_PRICE : {input_price:.10f}$\n"
        yield f"GEMINI_TOTAL_OUTPUT_PRICE : {output_price:.10f}$\n"
        yield f"GEMINI_TOTAL_PRICE : {(input_price + output_price):.10f}$\n"

    def send_message(self, message: str, force_include_all_files: bool = False) -> str:
        """
        Envoie un message et retourne la r√©ponse compl√®te
        
        Args:
            message: Le message √† envoyer
            force_include_all_files: Si True, inclut tous les fichiers m√™me s'ils ont d√©j√† √©t√© envoy√©s
        """
        if not self.chat:
            raise RuntimeError("Chat non initialis√©")
        
        content = [message]
        
        # D√©terminer quels fichiers ajouter
        if force_include_all_files:
            files_to_send = self.uploaded_files.copy()
        else:
            # Inclure automatiquement seulement les nouveaux fichiers
            files_to_send = self.get_new_files()
        
        # Ajouter les fichiers d√©termin√©s
        for file_info in files_to_send:
            content.append(file_info['file'])
        
        # Marquer les fichiers comme envoy√©s
        if files_to_send:
            self.mark_files_as_sent(files_to_send)
            print(f"üìé {len(files_to_send)} fichier(s) ajout√©(s) au contexte: {[f['name'] for f in files_to_send]}")
        
        response = self.chat.send_message(content)
        return response.text if hasattr(response, 'text') else str(response)