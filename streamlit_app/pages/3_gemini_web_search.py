import streamlit as st
import base64
import os
from dotenv import load_dotenv
from google import genai
from google.genai import types
import time
import pathlib

# Charger les variables d'environnement depuis le fichier .env
load_dotenv()

# Configuration de la page
st.set_page_config(
    page_title="Assistant Juridique Fran√ßais",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f4e79;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stTextArea textarea {
        font-size: 1.1rem;
    }
    .response-container {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid #1f4e79;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Fonction pour estimer le co√ªt
def estimate_cost(input_tokens=0, output_tokens=0, web_searches=0):
    """Estime le co√ªt bas√© sur les tokens et recherches web"""
    input_cost = (input_tokens / 1_000_000) * 3.0  # 3$ par million de tokens d'input
    output_cost = (output_tokens / 1_000_000) * 15.0  # 15$ par million de tokens d'output
    search_cost = web_searches * 0.035  # 0.035$ par recherche internet
    
    total_cost = input_cost + output_cost + search_cost
    return {
        'input_cost': input_cost,
        'output_cost': output_cost,
        'search_cost': search_cost,
        'total_cost': total_cost,
        'input_tokens': input_tokens,
        'output_tokens': output_tokens,
        'web_searches': web_searches
    }


# Fonction pour extraire les citations des m√©tadonn√©es
def extract_citations(response_metadata):
    """Extrait les citations des m√©tadonn√©es de grounding"""
    citations = {}
    
    if hasattr(response_metadata, 'grounding_metadata') and response_metadata.grounding_metadata:
        grounding_metadata = response_metadata.grounding_metadata
        
        # Extraire les chunks de grounding (sources)
        if hasattr(grounding_metadata, 'grounding_chunks') and grounding_metadata.grounding_chunks:
            for grounding_chunk in grounding_metadata.grounding_chunks:
                if (hasattr(grounding_chunk, 'web') and 
                    grounding_chunk.web is not None):
                    
                    web_info = grounding_chunk.web
                    title = getattr(web_info, 'title', 'Source inconnue')
                    uri = getattr(web_info, 'uri', '')
                    
                    # √âviter les doublons en utilisant l'URI comme cl√©
                    if uri and uri not in citations:
                        citations[uri] = {
                            'title': title,
                            'uri': uri
                        }
    
    return citations

# Fonction pour formater les citations
def format_citations(citations):
    """Formate les citations pour l'affichage"""
    if not citations:
        return ""
    
    citations_text = "\n\n---\n\n### üìö Sources utilis√©es :\n\n"
    
    for i, (uri, citation) in enumerate(citations.items(), 1):
        citations_text += f"**[{i}]** [{citation['title']}]({citation['uri']})\n\n"
    
    return citations_text

# Fonction pour traiter les fichiers upload√©s
def process_uploaded_files(uploaded_files):
    """Traite les fichiers upload√©s et retourne les parties pour Gemini"""
    file_parts = []
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            try:
                # Lire les bytes du fichier
                file_bytes = uploaded_file.read()
                
                # D√©terminer le type MIME bas√© sur l'extension
                file_extension = uploaded_file.name.lower().split('.')[-1]
                mime_type_map = {
                    'pdf': 'application/pdf',
                    'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
                    'doc': 'application/msword',
                    'txt': 'text/plain',
                    'jpg': 'image/jpeg',
                    'jpeg': 'image/jpeg',
                    'png': 'image/png',
                    'gif': 'image/gif',
                    'bmp': 'image/bmp'
                }
                
                mime_type = mime_type_map.get(file_extension, 'application/octet-stream')
                
                # Cr√©er une partie pour Gemini
                file_part = types.Part.from_bytes(
                    data=file_bytes,
                    mime_type=mime_type
                )
                file_parts.append(file_part)
                
                # Afficher les informations du fichier
                st.info(f"üìÅ Fichier trait√© : {uploaded_file.name} ({len(file_bytes)} bytes)")
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors du traitement du fichier {uploaded_file.name}: {str(e)}")
    
    return file_parts

# Fonction pour g√©n√©rer la r√©ponse
def generate_legal_response(chat_input_value):
    """G√©n√®re une r√©ponse juridique en utilisant l'API Gemini"""
    try:
        # Chargement des variables d'environnement
        load_dotenv()
        
        # V√©rification de la cl√© API
        api_key = os.environ.get("GEMINI_API_KEY") or st.secrets.get("GEMINI_API_KEY")
        if not api_key:
            st.error("‚ùå Cl√© API GEMINI_API_KEY non trouv√©e. Veuillez la configurer dans le fichier .env ou les secrets Streamlit.")
            return None
        
        # Initialisation du client
        client = genai.Client(api_key=api_key)
        model = "gemini-2.5-pro-preview-06-05"
        
        # Extraire le texte et les fichiers du chat_input
        if isinstance(chat_input_value, str):
            # Si c'est juste une string (exemple de question)
            question_text = chat_input_value
            uploaded_files = []
        else:
            # Si c'est un ChatInputValue avec potentiellement des fichiers
            question_text = chat_input_value.text if hasattr(chat_input_value, 'text') else str(chat_input_value)
            uploaded_files = chat_input_value.files if hasattr(chat_input_value, 'files') else []
        
        # Traiter les fichiers upload√©s
        file_parts = process_uploaded_files(uploaded_files)
        
        # Construire les parties du contenu
        content_parts = []
        
        # Ajouter les fichiers en premier
        content_parts.extend(file_parts)
        
        # Ajouter le texte de la question
        content_parts.append(types.Part.from_text(text=question_text))
        
        # Configuration du contenu
        contents = [
            types.Content(
                role="user",
                parts=content_parts,
            ),
        ]
        
        # Configuration des outils
        tools = [
            types.Tool(url_context=types.UrlContext()),
            types.Tool(google_search=types.GoogleSearch()),
        ]
        
        # date d'aujourd'hui 
        today = time.strftime("%Y-%m-%d")
        # Configuration de g√©n√©ration
        generate_content_config = types.GenerateContentConfig(
            thinking_config=types.ThinkingConfig(
                thinking_budget=-1,
            ),
            tools=tools,
            response_mime_type="text/plain",
            system_instruction=[
                types.Part.from_text(text="""Votre R√¥le : Vous √™tes un assistant de recherche juridique IA de premier ordre. Votre mission est de simuler une recherche juridique exhaustive et de haute qualit√©, en fournissant des r√©ponses rapides, fiables et pr√©cis√©ment sourc√©es, √† l'image des meilleures plateformes sp√©cialis√©es.
Voici la date d'aujourd'hui : {today}
Votre Processus de Recherche Simul√© :
Lorsque je vous pose une question, vous simulerez une recherche approfondie en consultant syst√©matiquement les sources de r√©f√©rence du droit fran√ßais et europ√©en suivantes :
Sources L√©gislatives et R√©glementaires :
Les codes, lois et d√©crets consolid√©s sur L√©gifrance.
Sources Jurisprudentielles :
La jurisprudence de la Cour de cassation (ordres judiciaire).
La jurisprudence du Conseil d'√âtat (ordre administratif).
Les d√©cisions pertinentes des Cours d'appel.
Sources Doctrinales :
Les bases de donn√©es juridiques de premier plan comme Dalloz.fr, Lexis 360 et Lextenso.
Les articles de revues juridiques sp√©cialis√©es (ex: Recueil Dalloz, Semaine Juridique - JCP).
Sources Institutionnelles et Pratiques :
Les fiches pratiques et les informations des sites gouvernementaux officiels comme service-public.fr et les sites des minist√®res.
Les analyses et commentaires publi√©s sur les blogs d'avocats ou d'universitaires reconnus pour leur expertise dans le domaine concern√©.
Vos Principes de R√©ponse :
Clart√© et D√©tails : R√©digez une r√©ponse claire, pr√©cise et allant au d√©tail (long). .
Fiabilit√© et Pr√©cision : Assurez-vous que chaque information est v√©rifi√©e √† travers les sources simul√©es. Si une information est incertaine ou si les sources sont contradictoires, signalez-le explicitement. N'inventez jamais une r√©ponse.
Sour√ßage Rigoureux : Citez syst√©matiquement vos sources ( NUMERO ET DATE INCLUS si possible) pour chaque information cl√©. Utilisez le format [Source, Ann√©e] (ex: [Cour de cassation, 2e civ., 15 mai 2023], [Dalloz.fr, 2022]) ou une URL directe si elle est pertinente et stable. Si aucune source cr√©dible n'a pu √™tre identifi√©e, indiquez [Source indisponible].
Neutralit√© : Adoptez un ton neutre et factuel.
Format de R√©ponse Obligatoire :
R√©sum√© :
Une explication bien structur√©e, synth√©tique et directe.
Citations :
[Nom de la source, Ann√©e]
[Lien direct si tu es s√ªr √† plus de 95% de sa v√©racit√© et qu'il ne s'agit pas d'une jurisprudence]""".format(today=today)),
            ],
        )
        
        # G√©n√©ration de la r√©ponse avec estimation des co√ªts et extraction des citations
        response_text = ""
        estimated_web_searches = 2  # Estimation bas√©e sur l'utilisation des outils de recherche
        citations = {}
        
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )
        
        # Extraire le texte de la r√©ponse
        if response.text:
            response_text = response.text
        
        # Extraire les citations si disponibles
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'grounding_metadata'):
                citations = extract_citations(candidate)
        
        # Estimation des co√ªts
        # Extraire les tokens usage_metadata
                if (hasattr(response, 'usage_metadata') and 
                    response.usage_metadata is not None):
                    
                    usage = response.usage_metadata
                    input_tokens = getattr(usage, 'prompt_token_count', 0)
                    output_tokens = getattr(usage, 'candidates_token_count', 0)
        
        # Ajouter les tokens des fichiers (estimation approximative)
        for file_part in file_parts:
            input_tokens += 1000  # Estimation moyenne par fichier
        
        cost_info = estimate_cost(input_tokens, output_tokens, estimated_web_searches)
        
        # Mettre √† jour le co√ªt total de la session
        if 'total_session_cost' in st.session_state:
            st.session_state.total_session_cost += cost_info['total_cost']
        
        # Ajouter les citations √† la r√©ponse
        citations_display = format_citations(citations)
        
        # Ajouter les informations de co√ªt √† la r√©ponse
        cost_display = f"""

---
        
### üí∞ Co√ªt estim√© de cette requ√™te :
- **Tokens d'entr√©e** : {cost_info['input_tokens']:,} tokens ‚Üí ${cost_info['input_cost']:.4f}
- **Tokens de sortie** : {cost_info['output_tokens']:,} tokens ‚Üí ${cost_info['output_cost']:.4f}
- **Recherches web** : {cost_info['web_searches']} recherche(s) ‚Üí ${cost_info['search_cost']:.4f}
- **üè∑Ô∏è Total estim√©** : **${cost_info['total_cost']:.4f}**

        """
        
        # Construire la r√©ponse finale avec citations et co√ªts
        final_response = response_text + citations_display + cost_display
        
        return final_response
        
    except Exception as e:
        st.error(f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse : {str(e)}")
        return None

# Interface principale
def main():
    # En-t√™te
    st.markdown('<div class="main-header">‚öñÔ∏è Assistant Juridique Fran√ßais</div>', unsafe_allow_html=True)
    

    # Sidebar avec informations
    with st.sidebar:
        st.header("üí∞ Tarification")
        st.write("""
          **Co√ªts par requ√™te :**
          - Input : **3$/M tokens**
          - Output : **15$/M tokens**
          - Recherche web : **0.035$/requ√™te**
        
          *Co√ªt moyen par question : ~0.04-0.1$*
        """)
        

        st.header("üîß Configuration")
        if st.button("üîÑ Effacer l'historique"):
            if 'chat_history' in st.session_state:
                st.session_state.chat_history = []
            if 'total_session_cost' in st.session_state:
                st.session_state.total_session_cost = 0.0
            st.rerun()
        
        st.header("üìñ Exemples de questions")
        example_questions = [
            "Quels sont les d√©lais de pr√©avis pour un licenciement ?",
            "Comment cr√©er une SAS ?",
            "Quelles sont les conditions pour un divorce par consentement mutuel ?",
            "Qu'est-ce que la l√©gitime d√©fense en droit p√©nal ?",
            "Comment contester une amende routi√®re ?"
        ]
        
        for i, question in enumerate(example_questions):
            if st.button(f"üìù {question[:50]}...", key=f"example_{i}"):
                # D√©clencher directement le traitement de l'exemple
                with st.spinner("üîç Recherche et analyse en cours..."):
                    # Ajouter la question √† l'historique
                    st.session_state.chat_history.append({
                        'type': 'question',
                        'content': question,
                        'timestamp': time.time()
                    })
                    
                    # G√©n√©rer la r√©ponse
                    response = generate_legal_response(question)
                    
                    if response:
                        # Ajouter la r√©ponse √† l'historique
                        st.session_state.chat_history.append({
                            'type': 'response',
                            'content': response,
                            'timestamp': time.time()
                        })
                        
                        st.rerun()

    # Zone de saisie avec chat_input
    user_question = st.chat_input(
        "üí¨ Posez votre question juridique...",
        key="chat_input",
        accept_file=True,
        file_type=["pdf","txt"]
    )
        
    # Gestion de l'historique des conversations
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Initialiser le co√ªt total de session
    if 'total_session_cost' not in st.session_state:
        st.session_state.total_session_cost = 0.0
    
    # Traitement de la question via chat_input
    if user_question:
        with st.spinner("üîç Recherche et analyse en cours..."):
            # Extraire le texte pour l'affichage dans l'historique
            if isinstance(user_question, str):
                display_text = user_question
            else:
                display_text = user_question.text if hasattr(user_question, 'text') else str(user_question)
                # Afficher les fichiers upload√©s
                if hasattr(user_question, 'files') and user_question.files:
                    files_info = f" [üìÅ {len(user_question.files)} fichier(s) joint(s)]"
                    display_text += files_info
            
            # Ajouter la question √† l'historique
            st.session_state.chat_history.append({
                'type': 'question',
                'content': display_text,
                'timestamp': time.time()
            })
            
            # G√©n√©rer la r√©ponse
            response = generate_legal_response(user_question)
            
            if response:
                # Ajouter la r√©ponse √† l'historique
                st.session_state.chat_history.append({
                    'type': 'response',
                    'content': response,
                    'timestamp': time.time()
                })
                
                st.rerun()
    
    # Affichage de l'historique des conversations
    if st.session_state.chat_history:
        
        # Afficher le co√ªt total de la session
        if st.session_state.total_session_cost > 0:
            st.info(f"üí∞ **Co√ªt total de la session : ${st.session_state.total_session_cost:.4f}**")
        
        
        # Afficher les conversations de la plus r√©cente √† la plus ancienne
        for i in range(len(st.session_state.chat_history) - 1, -1, -1):
            item = st.session_state.chat_history[i]
            
            if item['type'] == 'question':
                st.markdown(f"**‚ùì Question :** {item['content']}")
            else:  # response
                st.markdown("**ü§ñ R√©ponse :**")
                st.markdown(item['content'])
                st.markdown('</div>', unsafe_allow_html=True)
                st.markdown("---")

# Configuration de la cl√© API
def setup_api_key():
    st.sidebar.header("üîë Configuration API")
    
    # Charger les variables d'environnement
    load_dotenv()
    
    # V√©rifier si la cl√© API est d√©j√† configur√©e
    if not (os.environ.get("GEMINI_API_KEY") or st.secrets.get("GEMINI_API_KEY")):
        st.sidebar.warning("‚ö†Ô∏è Cl√© API Gemini requise")
        st.sidebar.info("üí° Cr√©ez un fichier `.env` avec : `GEMINI_API_KEY=votre_cl√©`")
        
        # Option pour saisir la cl√© API via l'interface
        api_key_input = st.sidebar.text_input(
            "Saisissez votre cl√© API Gemini :",
            type="password",
            help="Vous pouvez obtenir une cl√© API sur https://ai.google.dev/"
        )
        
        if api_key_input:
            os.environ["GEMINI_API_KEY"] = api_key_input
            st.sidebar.success("‚úÖ Cl√© API configur√©e avec succ√®s !")
    else:
        st.sidebar.success("‚úÖ Cl√© API configur√©e")

if __name__ == "__main__":
    setup_api_key()
    main()